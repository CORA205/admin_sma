import sqlite3
import os
import json
import time
import logging
from datetime import datetime
from typing import Dict, Optional, List
import asyncio

from fastapi import FastAPI, HTTPException, Request
from pydantic import BaseModel
from transformers import pipeline
from tavily import TavilyClient
from google.genai import Client
from langdetect import detect
from googletrans import Translator
from dotenv import load_dotenv

# ==================== CONFIGURATION ====================

load_dotenv()

TAVILY_API_KEY = os.getenv("TAVILY_API_KEY", "")
GENAI_KEY = os.getenv("GEMINI_API_KEY", "")

# Chargement configuration
with open("config.json", "r", encoding="utf-8") as f:
    config = json.load(f)

OFFICIAL_SOURCES = config["OFFICIAL_SOURCES"]

# Logging
if not os.path.exists("logs"):
    os.makedirs("logs")

logging.basicConfig(
    filename="logs/app.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# Chargement mod√®les
logger.info("Chargement du classificateur XLM-RoBERTa...")
classifier = pipeline(
    "zero-shot-classification",
    model="joeddav/xlm-roberta-large-xnli",
    tokenizer="xlm-roberta-large",
    use_fast=False
)

translator_global = Translator()

logger.info("Tous les mod√®les charg√©s avec succ√®s ‚úÖ")


# ==================== MOD√àLES PYDANTIC ====================

class Question(BaseModel):
    text: str
    session_id: Optional[str] = None



# =============== TRAITEMENT DES LANGUES =================

async def first_lang(text):
    """Traduction asynchrone vers le fran√ßais"""
    original_lang = detect(text)

    if original_lang != 'fr':
        # Ex√©cuter la traduction dans un thread s√©par√©
        translated_text = await asyncio.to_thread(
            translator_global.translate, text, dest='fr'
        )
        return translated_text.text, original_lang
    else:
        return text, original_lang


async def last_lang(text, original_lang):
    """Traduction asynchrone vers la langue originale"""
    if original_lang != 'fr':
        translated_text = await asyncio.to_thread(
            translator_global.translate, text, dest=original_lang
        )
        return translated_text.text
    return text


# ==================== BASE DE DONN√âES ====================

def init_db():
    """Initialise la base SQLite pour l'historique"""
    connection = sqlite3.connect('memory.db')
    c = connection.cursor()
    c.execute('''
        CREATE TABLE IF NOT EXISTS history (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            session_id TEXT,
            query TEXT,
            response TEXT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            confidence REAL,
            is_admin_topic BOOLEAN
        )
    ''')
    c.execute('''
        CREATE INDEX IF NOT EXISTS idx_session 
        ON history(session_id, timestamp DESC)
    ''')
    connection.commit()
    logger.info("Base de donnees initialisee")

init_db()


# ==================== AGENTS ====================

class BinaryClassificationAgent:
    """
    Agent de classification binaire pour filtrer les questions hors-sujet.
    Confiance √©lev√©e (0.85-0.98) vs classification multi-classes (0.25-0.40).
    """

    def __init__(self):
        self.classifier = classifier
        self.labels = [
            "question sur d√©marches administratives ou services publics b√©ninois",
            "question hors sujet administration, conversation g√©n√©rale ou autre"
        ]
        self._cache = {}
        self._cache_ttl = 1800  # 30min

    async def execute(self, text: str) -> Dict:
        """
        Classifie la question en admin/hors-sujet.

        Returns:
            {
                "is_admin_topic": bool,
                "confidence": float,
                "label": str
            }
        """
        cache_key = text.lower().strip()

        # Cache check
        if cache_key in self._cache:
            cached_data, timestamp = self._cache[cache_key]
            if time.time() - timestamp < self._cache_ttl:
                logger.info(f"Classification cache hit")
                return cached_data

        try:

            result = self.classifier(text, self.labels, multi_label=False)

            is_admin = result['labels'][0] == self.labels[0]
            confidence = result['scores'][0]

            # Boost pour mots-cl√©s administratifs √©vidents
            admin_keywords = [
                'passeport', 'cni', 'carte', 'identit√©', 'naissance', 'acte',
                'mariage', 'permis', 'conduire', 'imp√¥ts', 'taxe', 'douane',
                'entreprise', 'rccm', 'visa', 'certificat', 'attestation',
                'd√©claration', 'd√©douanement', 'immatriculation', 'greffier'
            ]

            if any(kw in text.lower() for kw in admin_keywords):
                confidence = min(1.0, confidence + 0.15)
                is_admin = True

            result_data = {
                "is_admin_topic": is_admin,
                "confidence": confidence,
                "label": result['labels'][0]
            }

            # Cache store
            self._cache[cache_key] = (result_data, time.time())

            logger.info(
                f"Classification: {'ADMIN' if is_admin else 'HORS-SUJET'} "
                f"(conf: {confidence:.2f})"
            )

            return result_data

        except Exception as e:
            logger.error(f"Erreur classification: {e}")
            # Fallback conservateur
            return {
                "is_admin_topic": True,  # On laisse passer en cas de doute
                "confidence": 0.5,
                "label": "erreur_classification"
            }


class SmartSearchAgent:
    """
    Agent de recherche intelligent via Tavily.
    Pas d'intent pr√©d√©fini : on laisse Tavily comprendre la requ√™te.
    """

    def __init__(self):
        self.client = TavilyClient(api_key=TAVILY_API_KEY)
        self._cache = {}
        self._cache_ttl = 86400 # 24h pour infos stables


    async def execute(
            self,
            user_query: str,
            force_refresh: bool = False
    ) -> Dict:

        search_query = user_query.strip()
        cache_key = search_query.lower()


        # Cache check
        if not force_refresh and cache_key in self._cache:
            cached_data, timestamp = self._cache[cache_key]
            if time.time() - timestamp < self._cache_ttl:
                logger.info(f"Recherche cache hit: {cache_key[:50]}...")
                return cached_data

        try:
            logger.info(f"Recherche Tavily: {search_query}")

            # Recherche asynchrone
            def _do_search():
                return self.client.search(
                    query=search_query,
                    max_results=5,
                    include_domains=OFFICIAL_SOURCES,
                    search_depth="advanced",
                    include_images=False
                )

            loop = asyncio.get_event_loop()
            response = await asyncio.wait_for(
                loop.run_in_executor(None, _do_search),
                timeout=20
            )

            if not response.get("results"):
                logger.warning("Tavily: Aucun r√©sultat")
                return self._fallback(user_query)

            result = self._process_results(response)

            # Cache store
            self._cache[cache_key] = (result, time.time())

            logger.info(f"Tavily: {len(result['sources'])} sources trouv√©es")
            return result

        except asyncio.TimeoutError:
            logger.error("Tavily timeout (20s)")
            return self._fallback(user_query)

        except Exception as e:
            logger.error(f"Erreur Tavily: {e}")
            return self._fallback(user_query)

    @staticmethod
    def _process_results(response: Dict) -> Dict:

        """Agr√®ge les r√©sultats Tavily"""
        results = response.get("results", [])

        # Agr√®ge TOUS les contenus (pas juste le premier)
        all_content = "\n\n--- NOUVELLE SOURCE ---\n\n".join([
            f"üìÑ Source: {r['url']}\n\n{r['content']}"
            for r in results[:5]
            if r.get('content')
        ])

        sources = [r["url"] for r in results if r.get("url")]

        return {
            "content": all_content,
            "sources": sources,
            "raw_results": results
        }

    @staticmethod
    def _fallback(query: str) -> Dict:
        """Fallback si Tavily √©choue"""
        return {
            "content": f"Aucune information officielle trouv√©e pour : '{query}'",
            "sources": [],
            "raw_results": []
        }


class SyntheseAgent:
    """
    Agent de synth√®se avec Gemini 2.5 Flash.
    Compatible google-genai v1.46.0.
    Utilise le chat endpoint pour g√©n√©rer du texte et renvoyer un JSON structur√©.
    """

    def __init__(self, api_key: str):
        self.client = Client(api_key=api_key)
        self.model = "gemini-2.5-flash"

    async def execute(self, search_results: Dict, user_query: str) -> Dict:
        content = search_results.get("content", "")

        if not content or len(content) < 100:
            return self._create_empty_response(search_results)

        prompt = self._build_prompt(user_query, content)

        try:
            logger.info("Appel Gemini ...")
            response = await self.client.aio.models.generate_content(
                model=self.model,
                contents=prompt
            )

            # R√©cup√©ration du texte g√©n√©r√©
            text_output = response.text
            logger.info(f"R√©ponse brute Gemini: {text_output}")

            # Parsing JSON
            try:
                result = json.loads(text_output.strip())
            except json.JSONDecodeError:
                logger.warning("Impossible de parser JSON Gemini, fallback appliqu√©")
                return self._create_fallback_response(text_output, search_results)

            result = self._clean_result(result)




            # Mapping final vers les cl√©s attendues
            mapped_result = {
                "reponse": result.get("reponse", ""),
                "pieces_requises": result.get("pieces_requises"),
                "cout": result.get("cout"),
                "delai_traitement": result.get("delai_traitement"),
                "lieux": result.get("lieux"),
                "etapes": result.get("etapes"),
                "sources": result.get("sources", search_results.get("sources", []))
            }

            logger.info("‚úÖ Synth√®se r√©ussie")
            return mapped_result

        except Exception as e:
            logger.error(f"Erreur Gemini: {e}", exc_info=True)
            return self._create_fallback_response(content, search_results)

    @staticmethod
    def _build_prompt(query: str, content: str) -> str:
        return f"""Tu es un assistant sp√©cialis√© dans l'extraction d'informations administratives b√©ninoises.

    **QUESTION DE L'UTILISATEUR:**
    {query}

    **CONTENU DES SOURCES OFFICIELLES:**
    {content[:4000]}

    **TA MISSION:**
    1. Lis attentivement le contenu ci-dessus
    2. Extrais TOUTES les informations structur√©es (pi√®ces, co√ªt, d√©lai, lieux, √©tapes)
    3. R√©ponds √† la question en 2-4 phrases claires
    4. Retourne un JSON valide sans ```json ```

    **EXEMPLE DE BONNE EXTRACTION:**

    Contenu brut: "Pi√®ces requises: CNI, Acte de naissance. Co√ªt: 25000 FCFA. D√©lai: 15 jours."

    R√©ponse JSON attendue:
    {{
      "reponse": "Pour obtenir le document, vous devez fournir votre CNI et votre acte de naissance. Le co√ªt est de 25 000 FCFA et le traitement prend 15 jours.",
      "pieces_requises": ["CNI", "Acte de naissance"],
      "cout": "25 000 FCFA",
      "delai_traitement": "15 jours",
      "lieux": null,
      "etapes": null,
      "sources": ["https://service-public.bj"]
    }}

    **TON TOUR MAINTENANT:**

    Analyse le contenu ci-dessus et retourne UN SEUL JSON avec ces cl√©s EXACTES:
    - "reponse" (string): R√©ponse synth√©tique en 2-4 phrases
    - "pieces_requises" (array ou null): Liste de TOUS les documents mentionn√©s
    - "cout" (string ou null): Montant EXACT en FCFA
    - "delai_traitement" (string ou null): Dur√©e EXACTE
    - "lieux" (array ou null): Liste des adresses/services
    - "etapes" (array ou null): Liste des √©tapes num√©rot√©es
    - "sources" (array): URLs des sources

    **R√àGLES ABSOLUES:**
    ‚úì EXTRAIS tout, n'invente rien
    ‚úì Utilise null (pas "", pas []) pour infos absentes
    ‚úì PAS de copier-coller du texte brut dans "reponse"
    ‚úì Commence directement par {{ (pas de texte avant)
    ‚úì Termine par }} (pas de texte apr√®s)

    JSON:"""
    @staticmethod
    def _clean_result(result: Dict) -> Dict:
        """Nettoie le r√©sultat Gemini"""
        for key in ["pieces_requises", "etapes"]:
            if key in result and isinstance(result[key], list) and not result[key]:
                result[key] = None
        for key in ["cout", "delai_traitement", "lieux"]:
            if key in result and result[key] == "":
                result[key] = None
        return result

    @staticmethod
    def _create_empty_response(search_results: Dict) -> Dict:
        """R√©ponse quand Tavily n'a rien trouv√©"""
        return {
            "reponse": "D√©sol√©, je n'ai trouv√© aucune information officielle sur ce sujet dans les sources gouvernementales b√©ninoises.",
            "pieces_requises": None,
            "cout": None,
            "delai_traitement": None,
            "lieux": None,
            "etapes": None,
            "sources": search_results.get("sources", [])
        }

    @staticmethod
    def _create_fallback_response(content: str, search_results: Dict) -> Dict:
        """Fallback si Gemini √©choue ou JSON invalide"""
        return {
            "reponse": content[:500] + "..." if len(content) > 500 else content,
            "pieces_requises": search_results.get("pieces_requises"),
            "cout": search_results.get("cout"),
            "delai_traitement": search_results.get("delai_traitement"),
            "lieux": search_results.get("lieux"),
            "etapes": search_results.get("etapes"),
            "sources": search_results.get("sources", [])
        }


class MemoireAgent:
    """Agent de m√©morisation des interactions"""

    @staticmethod
    def save_interaction(
            session_id: str,
            query: str,
            response_data: Dict,
            confidence: float,
            is_admin: bool
    ):
        """Sauvegarde l'interaction en base"""
        try:
            with sqlite3.connect('memory.db') as conn:
                c = conn.cursor()
                c.execute(
                    """INSERT INTO history 
                       (session_id, query, response, confidence, is_admin_topic)
                       VALUES (?, ?, ?, ?, ?)""",
                    (
                        session_id,
                        query,
                        json.dumps(response_data, ensure_ascii=False),
                        confidence,
                        is_admin
                    )
                )
                conn.commit()
        except Exception as e:
            logger.error(f"Erreur sauvegarde historique: {e}")

    @staticmethod
    def get_history(session_id: str, limit: int = 5) -> List[Dict]:
        """R√©cup√®re l'historique d'une session"""
        try:
            with sqlite3.connect('memory.db') as conn:
                c = conn.cursor()
                c.execute(
                    """SELECT query, response, timestamp, confidence 
                       FROM history 
                       WHERE session_id = ? 
                       ORDER BY timestamp DESC 
                       LIMIT ?""",
                    (session_id, limit)
                )
                rows = c.fetchall()
                return [
                    {
                        "query": r[0],
                        "response": json.loads(r[1]),
                        "timestamp": r[2],
                        "confidence": r[3]
                    }
                    for r in rows
                ]
        except Exception as e:
            logger.error(f"Erreur lecture historique: {e}")
            return []

    @staticmethod
    def cleanup_old_data(days: int = 90):
        """Nettoie les donn√©es anciennes"""
        try:
            with sqlite3.connect('memory.db') as conn:
                c = conn.cursor()
                c.execute(
                    f"DELETE FROM history WHERE timestamp < datetime('now', '-{days} days')"
                )
                deleted = c.rowcount
                conn.commit()
                logger.info(f"Nettoyage: {deleted} entr√©es supprim√©es (>{days}j)")
        except Exception as e:
            logger.error(f"Erreur nettoyage: {e}")


# ==================== API FASTAPI ====================

app = FastAPI(
    title="Assistant Administratif B√©nin (v2 - Architecture Simplifi√©e)",
    description="Syst√®me multi-agents avec classification binaire + Tavily + Gemini",
    version="2.0.0"
)


@app.post("/info")
async def get_info(q: Question):
    """
    Endpoint principal : r√©pond aux questions administratives en multilingue.
    """
    start_time = time.time()

    try:
        # ===== √âTAPE 0: D√âTECTION LANGUE + TRADUCTION SI N√âCESSAIRE =====
        logger.info(f"üåê Question re√ßue: '{q.text}'")

        try:
            question_fr, langue_origine = await first_lang(q.text)
            logger.info(f"üåê Langue d√©tect√©e: {langue_origine}")
            logger.info(
                f"üåê Question traduite vers fran√ßais: '{question_fr}'" if langue_origine != 'fr' else "üåê Question d√©j√† en fran√ßais, pas de traduction n√©cessaire")
        except Exception as e:
            logger.warning(f"‚ùå Erreur d√©tection/traduction langue, utilisation texte brut: {e}")
            question_fr = q.text
            langue_origine = 'fr'

        # ===== √âTAPE 1: CLASSIFICATION BINAIRE =====
        classifier_agent = BinaryClassificationAgent()
        classif = await classifier_agent.execute(question_fr)

        # ===== √âTAPE 2: FILTRE HORS-SUJET =====
        if not classif["is_admin_topic"] or classif["confidence"] < 0.65:
            logger.info(f"üö´ Question hors-sujet d√©tect√©e (conf: {classif['confidence']:.2f})")

            # Pr√©parer la r√©ponse hors-sujet (en fran√ßais d'abord)
            reponse_hors_sujet_fr = (
                "D√©sol√©, je suis sp√©cialis√© dans les d√©marches administratives "
                "et services publics b√©ninois. Je ne peux pas r√©pondre √† cette question. "
                "Exemples de ce que je peux vous aider : passeport, CNI, acte de naissance, "
                "permis de conduire, cr√©ation d'entreprise, imp√¥ts, etc."
            )

            # Traduire vers langue originale SI n√©cessaire
            if langue_origine != 'fr':
                translated_obj = await asyncio.to_thread(
                    translator_global.translate, reponse_hors_sujet_fr, langue_origine
                )
                reponse_finale = translated_obj.text

                logger.info(f"üåê R√©ponse hors-sujet traduite vers {langue_origine}")
            else:
                reponse_finale = reponse_hors_sujet_fr

            response_data = {
                "is_admin_topic": False,
                "confidence": classif["confidence"],
                "reponse": reponse_finale,
                "pieces_requises": None,
                "cout": None,
                "delai_traitement": None,
                "lieux": None,
                "etapes": None,
                "sources": [],
                "metadata": {
                    "label": classif["label"],
                    "langue_origine": langue_origine,
                    "execution_time_ms": int((time.time() - start_time) * 1000)
                }
            }

            # Sauvegarde historique
            if q.session_id:
                MemoireAgent.save_interaction(
                    q.session_id, q.text, response_data,
                    classif["confidence"], False
                )

            return response_data

        # ===== √âTAPE 3: RECHERCHE INTELLIGENTE =====
        logger.info("üîç Lancement de la recherche Tavily...")
        search_agent = SmartSearchAgent()
        search_results = await search_agent.execute(user_query=question_fr)

        # ===== √âTAPE 4: SYNTH√àSE AVEC GEMINI =====
        logger.info("üß† Synth√®se avec Gemini...")
        synth_agent = SyntheseAgent(api_key=GENAI_KEY)
        synthesis = await synth_agent.execute(search_results, question_fr)

        # ===== √âTAPE 5: CONSTRUCTION R√âPONSE =====
        execution_time_ms = int((time.time() - start_time) * 1000)

        response_data = {
            "is_admin_topic": True,
            "confidence": classif["confidence"],
            "reponse": synthesis.get("reponse", ""),
            "pieces_requises": synthesis.get("pieces_requises"),
            "cout": synthesis.get("cout"),
            "delai_traitement": synthesis.get("delai_traitement"),
            "lieux": synthesis.get("lieux"),
            "etapes": synthesis.get("etapes"),
            "sources": synthesis.get("sources", []),
            "metadata": {
                "label": classif["label"],
                "langue_origine": langue_origine,
                "execution_time_ms": execution_time_ms,
                "sources_trouvees": len(synthesis.get("sources", []))
            }
        }

        # ===== √âTAPE 6: TRADUCTION VERS LANGUE ORIGINALE =====
        if langue_origine != 'fr':
            logger.info(f"üåê Retraduction vers {langue_origine}...")
            try:
                fields_to_translate = []

                if response_data.get("reponse"):
                    fields_to_translate.append("reponse")
                if response_data.get("cout"):
                    fields_to_translate.append("cout")
                if response_data.get("delai_traitement"):
                    fields_to_translate.append("delai_traitement")


                translation_tasks = [
                    last_lang(response_data[field], langue_origine)
                    for field in fields_to_translate
                ]

                # Ex√©cute les traductions en parall√®le
                results = await asyncio.gather(*translation_tasks, return_exceptions=True)

                # Met √† jour les champs traduits ou log les erreurs
                for field, result in zip(fields_to_translate, results):
                    if isinstance(result, Exception):
                        logger.error(f"Erreur traduction champ '{field}': {result}")
                    else:
                        response_data[field] = result

                logger.info(f"‚úÖ Retraduction r√©ussie vers {langue_origine}")

            except Exception as e:
                logger.error(f"‚ùå Erreur retraduction: {e}")

        # ===== √âTAPE 7: M√âMORISATION =====
        if q.session_id:
            MemoireAgent.save_interaction(
                q.session_id, q.text, response_data,
                classif["confidence"], True
            )

        logger.info(
            f"‚úÖ Requ√™te trait√©e en {execution_time_ms}ms - "
            f"Langue: {langue_origine} - "
            f"Confiance: {classif['confidence']:.2f} - "
            f"Sources: {len(response_data['sources'])}"
        )

        return response_data

    except Exception as e:
        execution_time_ms = int((time.time() - start_time) * 1000)
        logger.error(f"‚ùå Erreur apr√®s {execution_time_ms}ms: {e}", exc_info=True)

        # R√©ponse d'erreur avec traduction si possible
        erreur_message = f"Erreur technique: {str(e)}"
        try:
            # Essayer de d√©tecter la langue depuis la question originale
            detected_lang = detect(q.text)
            if detected_lang != 'fr':
                translated_obj = await asyncio.to_thread(
                    translator_global.translate, erreur_message, detected_lang
                )
                erreur_message = translated_obj.text

        except Exception as trans_error:

            logger.error(f"Erreur d√©tection langue pour erreur: {trans_error}")

        raise HTTPException(
            status_code=500,
            detail=erreur_message
        )

@app.get("/health")
async def health_check():
    """V√©rifie l'√©tat du syst√®me"""
    return {
        "status": "healthy",
        "version": "2.0.0",
        "timestamp": datetime.now().isoformat(),
        "components": {
            "classifier": "XLM-RoBERTa",
            "search": "Tavily",
            "synthesis": "Gemini 2.5 Flash",
            "database": "SQLite"
        }
    }


@app.get("/sources")
async def get_sources():
    """Liste des sources officielles utilis√©es"""
    return {
        "official_domains": OFFICIAL_SOURCES,
        "count": len(OFFICIAL_SOURCES)
    }


@app.get("/history/{session_id}")
async def get_session_history(session_id: str, limit: int = 10):
    """R√©cup√®re l'historique d'une session"""
    history = MemoireAgent.get_history(session_id, limit)
    return {
        "session_id": session_id,
        "count": len(history),
        "history": history
    }


@app.post("/cleanup")
async def cleanup_database(days: int = 90):
    """Nettoie les donn√©es anciennes (admin endpoint)"""
    MemoireAgent.cleanup_old_data(days)
    return {"status": "cleanup_completed", "days": days}


@app.middleware("http")
async def log_performance(request: Request, call_next):
    """Middleware de logging des performances"""
    start_time = time.time()
    response = await call_next(request)
    process_time_ms = int((time.time() - start_time) * 1000)

    logger.info(
        f"{request.method} {request.url.path} - "
        f"Status: {response.status_code} - "
        f"Time: {process_time_ms}ms"
    )

    response.headers["X-Process-Time"] = f"{process_time_ms}ms"
    response.headers["X-Version"] = "2.0.0"

    return response


# ==================== D√âMARRAGE ====================

if __name__ == "__main__":
    import uvicorn

    logger.info("üöÄ D√©marrage Assistant Administratif B√©nin v2.0")
    logger.info(f"Sources officielles: {len(OFFICIAL_SOURCES)}")

    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )